{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f756c054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI Zaki_env\\zaki_env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.0534 - loss: 0.6629 - val_accuracy: 0.0840 - val_loss: 0.5597\n",
      "Epoch 2/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1004 - loss: 0.5665 - val_accuracy: 0.1110 - val_loss: 0.5307\n",
      "Epoch 3/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1046 - loss: 0.5430 - val_accuracy: 0.0700 - val_loss: 0.5203\n",
      "Epoch 4/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0816 - loss: 0.5268 - val_accuracy: 0.0760 - val_loss: 0.5154\n",
      "Epoch 5/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0823 - loss: 0.5204 - val_accuracy: 0.1000 - val_loss: 0.5075\n",
      "Epoch 6/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0967 - loss: 0.5126 - val_accuracy: 0.0650 - val_loss: 0.5037\n",
      "Epoch 7/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0904 - loss: 0.5069 - val_accuracy: 0.1050 - val_loss: 0.4971\n",
      "Epoch 8/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0912 - loss: 0.5034 - val_accuracy: 0.0490 - val_loss: 0.4946\n",
      "Epoch 9/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0865 - loss: 0.5033 - val_accuracy: 0.0970 - val_loss: 0.4958\n",
      "Epoch 10/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1121 - loss: 0.4912 - val_accuracy: 0.0840 - val_loss: 0.4851\n",
      "Epoch 11/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1031 - loss: 0.4915 - val_accuracy: 0.1360 - val_loss: 0.4831\n",
      "Epoch 12/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0965 - loss: 0.4873 - val_accuracy: 0.1260 - val_loss: 0.4810\n",
      "Epoch 13/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1028 - loss: 0.4924 - val_accuracy: 0.0620 - val_loss: 0.4787\n",
      "Epoch 14/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1037 - loss: 0.4833 - val_accuracy: 0.0740 - val_loss: 0.4703\n",
      "Epoch 15/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1094 - loss: 0.4812 - val_accuracy: 0.0840 - val_loss: 0.4680\n",
      "Epoch 16/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1065 - loss: 0.4735 - val_accuracy: 0.1270 - val_loss: 0.4653\n",
      "Epoch 17/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1214 - loss: 0.4739 - val_accuracy: 0.1670 - val_loss: 0.4605\n",
      "Epoch 18/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1500 - loss: 0.4730 - val_accuracy: 0.1560 - val_loss: 0.4570\n",
      "Epoch 19/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1317 - loss: 0.4723 - val_accuracy: 0.1890 - val_loss: 0.4546\n",
      "Epoch 20/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1423 - loss: 0.4588 - val_accuracy: 0.1390 - val_loss: 0.4521\n",
      "Epoch 21/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1286 - loss: 0.4621 - val_accuracy: 0.2030 - val_loss: 0.4497\n",
      "Epoch 22/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1600 - loss: 0.4625 - val_accuracy: 0.1550 - val_loss: 0.4442\n",
      "Epoch 23/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1383 - loss: 0.4581 - val_accuracy: 0.1500 - val_loss: 0.4414\n",
      "Epoch 24/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1525 - loss: 0.4510 - val_accuracy: 0.1440 - val_loss: 0.4383\n",
      "Epoch 25/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1594 - loss: 0.4502 - val_accuracy: 0.1330 - val_loss: 0.4372\n",
      "Epoch 26/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1566 - loss: 0.4484 - val_accuracy: 0.1900 - val_loss: 0.4293\n",
      "Epoch 27/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1717 - loss: 0.4518 - val_accuracy: 0.1650 - val_loss: 0.4253\n",
      "Epoch 28/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1647 - loss: 0.4462 - val_accuracy: 0.1900 - val_loss: 0.4254\n",
      "Epoch 29/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1760 - loss: 0.4441 - val_accuracy: 0.1840 - val_loss: 0.4191\n",
      "Epoch 30/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1844 - loss: 0.4348 - val_accuracy: 0.1870 - val_loss: 0.4151\n",
      "Epoch 31/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1852 - loss: 0.4371 - val_accuracy: 0.2040 - val_loss: 0.4129\n",
      "Epoch 32/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1944 - loss: 0.4322 - val_accuracy: 0.1870 - val_loss: 0.4068\n",
      "Epoch 33/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2051 - loss: 0.4297 - val_accuracy: 0.2090 - val_loss: 0.4027\n",
      "Epoch 34/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1995 - loss: 0.4216 - val_accuracy: 0.1990 - val_loss: 0.4023\n",
      "Epoch 35/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1877 - loss: 0.4265 - val_accuracy: 0.2090 - val_loss: 0.3955\n",
      "Epoch 36/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2083 - loss: 0.4201 - val_accuracy: 0.2020 - val_loss: 0.3947\n",
      "Epoch 37/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2161 - loss: 0.4186 - val_accuracy: 0.2160 - val_loss: 0.3900\n",
      "Epoch 38/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2116 - loss: 0.4135 - val_accuracy: 0.2330 - val_loss: 0.3868\n",
      "Epoch 39/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2185 - loss: 0.4105 - val_accuracy: 0.2310 - val_loss: 0.3853\n",
      "Epoch 40/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2010 - loss: 0.4031 - val_accuracy: 0.2250 - val_loss: 0.3837\n",
      "Epoch 41/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2224 - loss: 0.4092 - val_accuracy: 0.2400 - val_loss: 0.3825\n",
      "Epoch 42/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2161 - loss: 0.3982 - val_accuracy: 0.2240 - val_loss: 0.3754\n",
      "Epoch 43/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1990 - loss: 0.4053 - val_accuracy: 0.2520 - val_loss: 0.3739\n",
      "Epoch 44/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2367 - loss: 0.3975 - val_accuracy: 0.2540 - val_loss: 0.3692\n",
      "Epoch 45/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2269 - loss: 0.4013 - val_accuracy: 0.2450 - val_loss: 0.3660\n",
      "Epoch 46/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2208 - loss: 0.4035 - val_accuracy: 0.2460 - val_loss: 0.3629\n",
      "Epoch 47/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2413 - loss: 0.3924 - val_accuracy: 0.2620 - val_loss: 0.3638\n",
      "Epoch 48/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2229 - loss: 0.3938 - val_accuracy: 0.2680 - val_loss: 0.3586\n",
      "Epoch 49/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2309 - loss: 0.3924 - val_accuracy: 0.2550 - val_loss: 0.3565\n",
      "Epoch 50/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2147 - loss: 0.3933 - val_accuracy: 0.2850 - val_loss: 0.3542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI Zaki_env\\zaki_env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0663 - loss: 0.6614 - val_accuracy: 0.0640 - val_loss: 0.5459\n",
      "Epoch 2/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0975 - loss: 0.5426 - val_accuracy: 0.0750 - val_loss: 0.5200\n",
      "Epoch 3/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0869 - loss: 0.5256 - val_accuracy: 0.1090 - val_loss: 0.5050\n",
      "Epoch 4/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0771 - loss: 0.5106 - val_accuracy: 0.1000 - val_loss: 0.4948\n",
      "Epoch 5/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0870 - loss: 0.4973 - val_accuracy: 0.0910 - val_loss: 0.4868\n",
      "Epoch 6/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1013 - loss: 0.4877 - val_accuracy: 0.1030 - val_loss: 0.4814\n",
      "Epoch 7/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1078 - loss: 0.4896 - val_accuracy: 0.0970 - val_loss: 0.4759\n",
      "Epoch 8/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0924 - loss: 0.4782 - val_accuracy: 0.0970 - val_loss: 0.4681\n",
      "Epoch 9/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0917 - loss: 0.4707 - val_accuracy: 0.1540 - val_loss: 0.4627\n",
      "Epoch 10/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1126 - loss: 0.4760 - val_accuracy: 0.1220 - val_loss: 0.4566\n",
      "Epoch 11/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1008 - loss: 0.4667 - val_accuracy: 0.1440 - val_loss: 0.4506\n",
      "Epoch 12/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1074 - loss: 0.4640 - val_accuracy: 0.1230 - val_loss: 0.4431\n",
      "Epoch 13/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1185 - loss: 0.4548 - val_accuracy: 0.1020 - val_loss: 0.4378\n",
      "Epoch 14/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1017 - loss: 0.4469 - val_accuracy: 0.0860 - val_loss: 0.4322\n",
      "Epoch 15/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1116 - loss: 0.4439 - val_accuracy: 0.1030 - val_loss: 0.4293\n",
      "Epoch 16/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1073 - loss: 0.4360 - val_accuracy: 0.1110 - val_loss: 0.4234\n",
      "Epoch 17/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1111 - loss: 0.4392 - val_accuracy: 0.1240 - val_loss: 0.4214\n",
      "Epoch 18/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1070 - loss: 0.4387 - val_accuracy: 0.1260 - val_loss: 0.4137\n",
      "Epoch 19/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1235 - loss: 0.4241 - val_accuracy: 0.0920 - val_loss: 0.4084\n",
      "Epoch 20/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1220 - loss: 0.4290 - val_accuracy: 0.1530 - val_loss: 0.4067\n",
      "Epoch 21/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1169 - loss: 0.4183 - val_accuracy: 0.1190 - val_loss: 0.4010\n",
      "Epoch 22/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1135 - loss: 0.4213 - val_accuracy: 0.1290 - val_loss: 0.3962\n",
      "Epoch 23/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1168 - loss: 0.4184 - val_accuracy: 0.1130 - val_loss: 0.3993\n",
      "Epoch 24/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1169 - loss: 0.4158 - val_accuracy: 0.1380 - val_loss: 0.3909\n",
      "Epoch 25/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1193 - loss: 0.4147 - val_accuracy: 0.1200 - val_loss: 0.3909\n",
      "Epoch 26/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1032 - loss: 0.4107 - val_accuracy: 0.1270 - val_loss: 0.3820\n",
      "Epoch 27/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1201 - loss: 0.4084 - val_accuracy: 0.1260 - val_loss: 0.3775\n",
      "Epoch 28/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1233 - loss: 0.4073 - val_accuracy: 0.1240 - val_loss: 0.3725\n",
      "Epoch 29/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1229 - loss: 0.4080 - val_accuracy: 0.1550 - val_loss: 0.3700\n",
      "Epoch 30/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1175 - loss: 0.4021 - val_accuracy: 0.1620 - val_loss: 0.3655\n",
      "Epoch 31/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1294 - loss: 0.3928 - val_accuracy: 0.1560 - val_loss: 0.3638\n",
      "Epoch 32/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1308 - loss: 0.3951 - val_accuracy: 0.1520 - val_loss: 0.3608\n",
      "Epoch 33/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1506 - loss: 0.3908 - val_accuracy: 0.1530 - val_loss: 0.3561\n",
      "Epoch 34/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1367 - loss: 0.3888 - val_accuracy: 0.1780 - val_loss: 0.3518\n",
      "Epoch 35/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1455 - loss: 0.3881 - val_accuracy: 0.1630 - val_loss: 0.3483\n",
      "Epoch 36/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1532 - loss: 0.3870 - val_accuracy: 0.2010 - val_loss: 0.3473\n",
      "Epoch 37/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1688 - loss: 0.3824 - val_accuracy: 0.2560 - val_loss: 0.3415\n",
      "Epoch 38/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1624 - loss: 0.3782 - val_accuracy: 0.1670 - val_loss: 0.3400\n",
      "Epoch 39/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1384 - loss: 0.3758 - val_accuracy: 0.1940 - val_loss: 0.3355\n",
      "Epoch 40/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1657 - loss: 0.3733 - val_accuracy: 0.2120 - val_loss: 0.3337\n",
      "Epoch 41/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1651 - loss: 0.3758 - val_accuracy: 0.2200 - val_loss: 0.3266\n",
      "Epoch 42/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1734 - loss: 0.3672 - val_accuracy: 0.2070 - val_loss: 0.3272\n",
      "Epoch 43/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1742 - loss: 0.3702 - val_accuracy: 0.2130 - val_loss: 0.3273\n",
      "Epoch 44/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1849 - loss: 0.3617 - val_accuracy: 0.2700 - val_loss: 0.3196\n",
      "Epoch 45/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1992 - loss: 0.3630 - val_accuracy: 0.2280 - val_loss: 0.3181\n",
      "Epoch 46/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1850 - loss: 0.3679 - val_accuracy: 0.2510 - val_loss: 0.3151\n",
      "Epoch 47/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1899 - loss: 0.3604 - val_accuracy: 0.2280 - val_loss: 0.3089\n",
      "Epoch 48/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1775 - loss: 0.3514 - val_accuracy: 0.2720 - val_loss: 0.3088\n",
      "Epoch 49/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1978 - loss: 0.3570 - val_accuracy: 0.2320 - val_loss: 0.3079\n",
      "Epoch 50/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2018 - loss: 0.3513 - val_accuracy: 0.2430 - val_loss: 0.3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A (Minor-only): Accuracy = 28.50% | Loss = 0.3542\n",
      "Model B (Full-data): Accuracy = 24.30% | Loss = 0.3027\n",
      "\n",
      "ğŸ“Š Model A (Minor-only) Results:\n",
      "Accuracy: 28.50% | Loss: 0.3542\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "ğŸ” Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Weak       0.88      0.96      0.92     10689\n",
      "        Weak       0.88      0.66      0.76      4311\n",
      "\n",
      "    accuracy                           0.88     15000\n",
      "   macro avg       0.88      0.81      0.84     15000\n",
      "weighted avg       0.88      0.88      0.87     15000\n",
      "\n",
      "[[10304   385]\n",
      " [ 1445  2866]]\n",
      "\n",
      "ğŸ“Š Model B (Full-data) Results:\n",
      "Accuracy: 24.30% | Loss: 0.3027\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "ğŸ” Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Weak       0.90      0.99      0.95     10807\n",
      "        Weak       0.97      0.73      0.83      4193\n",
      "\n",
      "    accuracy                           0.92     15000\n",
      "   macro avg       0.94      0.86      0.89     15000\n",
      "weighted avg       0.92      0.92      0.91     15000\n",
      "\n",
      "[[10712    95]\n",
      " [ 1144  3049]]\n",
      "Minor-only label distribution: [53214 21786]\n",
      "Full-data label distribution: [53645 21355]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\n",
      "Subject-wise Prediction Comparison (Sample Student):\n",
      "--------------------------------------------------------------\n",
      "Subject                                       Actual Weak (A) Predicted (A)   Actual Weak (B) Predicted (B)  \n",
      "--------------------------------------------------------------\n",
      "Algorithm_&_Program_Design                    No              No              No              No             \n",
      "Database_Management_Systems                   No              No              No              No             \n",
      "Programming_with_Java                         No              No              No              No             \n",
      "Digital_Logic_&_Computer_Architecture         No              No              No              No             \n",
      "Software_Engineering                          No              No              No              No             \n",
      "Theoretical_Computer_Science                  No              No              No              No             \n",
      "Advanced_Data_Structures                      No              No              No              No             \n",
      "Data_Communication_&_Networks                 No              No              No              No             \n",
      "Operating_Systems_&_Shell_Programming         No              No              No              No             \n",
      "AI_&_ML                                       Yes             No              No              No             \n",
      "Software_Testing_&_QA                         No              No              No              No             \n",
      "Analysis_&_Design_of_Algorithms               No              No              No              No             \n",
      "Data_Mining_&_Warehousing                     No              No              No              No             \n",
      "Information_&_Cybersecurity                   No              No              No              No             \n",
      "Cloud_Computing                               No              No              No              No             \n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import joblib\n",
    "\n",
    "# Load dataset (with archetypes and masking logic)\n",
    "df = pd.read_csv(\"MCA_Student_Performance_Balanced.csv\")\n",
    "subjects = [col.replace(\"_Minor1\", \"\") for col in df.columns if \"_Minor1\" in col]\n",
    "\n",
    "def prepare_features_targets(df, subjects, threshold, include_endsem=True):\n",
    "    feature_columns = []\n",
    "    target_columns = []\n",
    "    for sub in subjects:\n",
    "        feature_columns.extend([f\"{sub}_Minor1\", f\"{sub}_Minor2\"])\n",
    "        if include_endsem:\n",
    "            feature_columns.append(f\"{sub}_EndSem\")\n",
    "    X = df[feature_columns]\n",
    "    for sub in subjects:\n",
    "        min1 = df[f\"{sub}_Minor1\"]\n",
    "        min2 = df[f\"{sub}_Minor2\"]\n",
    "        endsem = df[f\"{sub}_EndSem\"] if include_endsem else 0\n",
    "        # For minors-only: threshold should be realistic for only two minors (e.g., 24 out of 40)\n",
    "        # For minors+endsem: threshold higher (e.g., 60 or another realistic sum)\n",
    "        total_score = min1 + min2 + (endsem if include_endsem else 0)\n",
    "        is_missing = (min1 == 0) & (min2 == 0) & ((endsem == 0) if include_endsem else True)\n",
    "        df[f\"{sub}_IsWeak\"] = np.where(is_missing, 0, (total_score < threshold).astype(int))\n",
    "        target_columns.append(f\"{sub}_IsWeak\")\n",
    "    y = df[target_columns]\n",
    "    return X, y\n",
    "\n",
    "def scale_and_split_save_scaler(X, y, scaler_filename):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    return train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def build_model(input_dim, output_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, input_dim=input_dim, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
    "        Dense(32, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.25),\n",
    "        Dense(output_dim, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Model A (Minors only): threshold = 24 (for two minors, each max 20)\n",
    "X_minor, y_minor = prepare_features_targets(df, subjects, 24, include_endsem=False)\n",
    "X_train_A, X_test_A, y_train_A, y_test_A = scale_and_split_save_scaler(X_minor, y_minor, \"minmax_scaler_minor.pkl\")\n",
    "model_A = build_model(X_train_A.shape[1], len(subjects))\n",
    "history_A = model_A.fit(X_train_A, y_train_A, validation_data=(X_test_A, y_test_A), epochs=50, batch_size=16, verbose=1)\n",
    "model_A.save(\"WeaknessPredictor_MinorsOnly.h5\")\n",
    "\n",
    "# Model B (Minors + EndSem): threshold = 60 (e.g. two minors + one endsem: each max 20/20/60)\n",
    "X_full, y_full = prepare_features_targets(df, subjects, 60, include_endsem=True)\n",
    "X_train_B, X_test_B, y_train_B, y_test_B = scale_and_split_save_scaler(X_full, y_full, \"minmax_scaler_full.pkl\")\n",
    "model_B = build_model(X_train_B.shape[1], len(subjects))\n",
    "history_B = model_B.fit(X_train_B, y_train_B, validation_data=(X_test_B, y_test_B), epochs=50, batch_size=16, verbose=1)\n",
    "model_B.save(\"WeaknessPredictor_FullData.h5\")\n",
    "\n",
    "# --- Evaluation & Metrics ---\n",
    "loss_A, acc_A = model_A.evaluate(X_test_A, y_test_A, verbose=0)\n",
    "loss_B, acc_B = model_B.evaluate(X_test_B, y_test_B, verbose=0)\n",
    "print(f\"Model A (Minor-only): Accuracy = {acc_A*100:.2f}% | Loss = {loss_A:.4f}\")\n",
    "print(f\"Model B (Full-data): Accuracy = {acc_B*100:.2f}% | Loss = {loss_B:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“Š Model A (Minor-only) Results:\")\n",
    "print(f\"Accuracy: {acc_A*100:.2f}% | Loss: {loss_A:.4f}\")\n",
    "y_pred_A = (model_A.predict(X_test_A) > 0.5).astype(int)\n",
    "print(\"\\nğŸ” Overall Classification Report:\")\n",
    "print(classification_report(y_test_A.values.ravel(), y_pred_A.ravel(), target_names=[\"Not Weak\", \"Weak\"]))\n",
    "print(confusion_matrix(y_test_A.values.ravel(), y_pred_A.ravel()))\n",
    "\n",
    "print(\"\\nğŸ“Š Model B (Full-data) Results:\")\n",
    "print(f\"Accuracy: {acc_B*100:.2f}% | Loss: {loss_B:.4f}\")\n",
    "y_pred_B = (model_B.predict(X_test_B) > 0.5).astype(int)\n",
    "print(\"\\nğŸ” Overall Classification Report:\")\n",
    "print(classification_report(y_test_B.values.ravel(), y_pred_B.ravel(), target_names=[\"Not Weak\", \"Weak\"]))\n",
    "print(confusion_matrix(y_test_B.values.ravel(), y_pred_B.ravel()))\n",
    "\n",
    "print(\"Minor-only label distribution:\", np.bincount(y_minor.values.ravel()))\n",
    "print(\"Full-data label distribution:\", np.bincount(y_full.values.ravel()))\n",
    "\n",
    "# --- Sample predictions for a test student ---\n",
    "sample_A = np.expand_dims(X_test_A[0], axis=0)\n",
    "pred_A = (model_A.predict(sample_A)[0] > 0.5).astype(int)\n",
    "actual_A = y_test_A.iloc[0].values\n",
    "\n",
    "sample_B = np.expand_dims(X_test_B[0], axis=0)\n",
    "pred_B = (model_B.predict(sample_B)[0] > 0.5).astype(int)\n",
    "actual_B = y_test_B.iloc[0].values\n",
    "\n",
    "print(\"\\nSubject-wise Prediction Comparison (Sample Student):\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(f\"{'Subject':<45} {'Actual Weak (A)':<15} {'Predicted (A)':<15} {'Actual Weak (B)':<15} {'Predicted (B)':<15}\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "for i, sub in enumerate(subjects):\n",
    "    a_actual = \"Yes\" if actual_A[i] == 1 else \"No\"\n",
    "    a_pred = \"Yes\" if pred_A[i] == 1 else \"No\"\n",
    "    b_actual = \"Yes\" if actual_B[i] == 1 else \"No\"\n",
    "    b_pred = \"Yes\" if pred_B[i] == 1 else \"No\"\n",
    "    print(f\"{sub:<45} {a_actual:<15} {a_pred:<15} {b_actual:<15} {b_pred:<15}\")\n",
    "print(\"--------------------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zaki_env (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
