{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f756c054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\AI Zaki_env\\zaki_env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0849 - loss: 0.6662 - val_accuracy: 0.0390 - val_loss: 0.5543\n",
      "Epoch 2/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0782 - loss: 0.5620 - val_accuracy: 0.0660 - val_loss: 0.5286\n",
      "Epoch 3/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0806 - loss: 0.5294 - val_accuracy: 0.0940 - val_loss: 0.5208\n",
      "Epoch 4/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0673 - loss: 0.5285 - val_accuracy: 0.1290 - val_loss: 0.5150\n",
      "Epoch 5/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0868 - loss: 0.5170 - val_accuracy: 0.0790 - val_loss: 0.5102\n",
      "Epoch 6/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0878 - loss: 0.5146 - val_accuracy: 0.0940 - val_loss: 0.5042\n",
      "Epoch 7/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0801 - loss: 0.5069 - val_accuracy: 0.0830 - val_loss: 0.5003\n",
      "Epoch 8/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0901 - loss: 0.5066 - val_accuracy: 0.0880 - val_loss: 0.4963\n",
      "Epoch 9/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0850 - loss: 0.5035 - val_accuracy: 0.1200 - val_loss: 0.4965\n",
      "Epoch 10/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0945 - loss: 0.4982 - val_accuracy: 0.1340 - val_loss: 0.4887\n",
      "Epoch 11/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0876 - loss: 0.4935 - val_accuracy: 0.1340 - val_loss: 0.4832\n",
      "Epoch 12/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0825 - loss: 0.4899 - val_accuracy: 0.1220 - val_loss: 0.4786\n",
      "Epoch 13/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0828 - loss: 0.4882 - val_accuracy: 0.1160 - val_loss: 0.4742\n",
      "Epoch 14/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0910 - loss: 0.4815 - val_accuracy: 0.1150 - val_loss: 0.4710\n",
      "Epoch 15/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0840 - loss: 0.4761 - val_accuracy: 0.1040 - val_loss: 0.4645\n",
      "Epoch 16/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0774 - loss: 0.4727 - val_accuracy: 0.1110 - val_loss: 0.4611\n",
      "Epoch 17/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0864 - loss: 0.4674 - val_accuracy: 0.1140 - val_loss: 0.4569\n",
      "Epoch 18/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0734 - loss: 0.4613 - val_accuracy: 0.0910 - val_loss: 0.4526\n",
      "Epoch 19/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0730 - loss: 0.4633 - val_accuracy: 0.1190 - val_loss: 0.4489\n",
      "Epoch 20/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0884 - loss: 0.4629 - val_accuracy: 0.1040 - val_loss: 0.4464\n",
      "Epoch 21/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0738 - loss: 0.4619 - val_accuracy: 0.1100 - val_loss: 0.4430\n",
      "Epoch 22/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0801 - loss: 0.4582 - val_accuracy: 0.1100 - val_loss: 0.4389\n",
      "Epoch 23/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0718 - loss: 0.4571 - val_accuracy: 0.1240 - val_loss: 0.4348\n",
      "Epoch 24/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0770 - loss: 0.4493 - val_accuracy: 0.1280 - val_loss: 0.4334\n",
      "Epoch 25/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0930 - loss: 0.4549 - val_accuracy: 0.1080 - val_loss: 0.4281\n",
      "Epoch 26/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0671 - loss: 0.4451 - val_accuracy: 0.1040 - val_loss: 0.4254\n",
      "Epoch 27/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0787 - loss: 0.4409 - val_accuracy: 0.1200 - val_loss: 0.4217\n",
      "Epoch 28/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0830 - loss: 0.4372 - val_accuracy: 0.1140 - val_loss: 0.4185\n",
      "Epoch 29/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0875 - loss: 0.4367 - val_accuracy: 0.1280 - val_loss: 0.4158\n",
      "Epoch 30/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0835 - loss: 0.4317 - val_accuracy: 0.1230 - val_loss: 0.4127\n",
      "Epoch 31/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0753 - loss: 0.4361 - val_accuracy: 0.1150 - val_loss: 0.4070\n",
      "Epoch 32/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0879 - loss: 0.4283 - val_accuracy: 0.1440 - val_loss: 0.4028\n",
      "Epoch 33/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0859 - loss: 0.4243 - val_accuracy: 0.1270 - val_loss: 0.3997\n",
      "Epoch 34/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0858 - loss: 0.4192 - val_accuracy: 0.1210 - val_loss: 0.3960\n",
      "Epoch 35/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0842 - loss: 0.4210 - val_accuracy: 0.1090 - val_loss: 0.3908\n",
      "Epoch 36/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1069 - loss: 0.4129 - val_accuracy: 0.1570 - val_loss: 0.3871\n",
      "Epoch 37/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1028 - loss: 0.4104 - val_accuracy: 0.1240 - val_loss: 0.3845\n",
      "Epoch 38/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1091 - loss: 0.4110 - val_accuracy: 0.1410 - val_loss: 0.3805\n",
      "Epoch 39/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1080 - loss: 0.4052 - val_accuracy: 0.1280 - val_loss: 0.3782\n",
      "Epoch 40/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0967 - loss: 0.4107 - val_accuracy: 0.1400 - val_loss: 0.3730\n",
      "Epoch 41/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1134 - loss: 0.4081 - val_accuracy: 0.1440 - val_loss: 0.3699\n",
      "Epoch 42/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1076 - loss: 0.3980 - val_accuracy: 0.1480 - val_loss: 0.3664\n",
      "Epoch 43/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1066 - loss: 0.3985 - val_accuracy: 0.1610 - val_loss: 0.3625\n",
      "Epoch 44/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1104 - loss: 0.3996 - val_accuracy: 0.1440 - val_loss: 0.3616\n",
      "Epoch 45/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1081 - loss: 0.3962 - val_accuracy: 0.1520 - val_loss: 0.3567\n",
      "Epoch 46/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1197 - loss: 0.3923 - val_accuracy: 0.1450 - val_loss: 0.3547\n",
      "Epoch 47/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1291 - loss: 0.3879 - val_accuracy: 0.1320 - val_loss: 0.3508\n",
      "Epoch 48/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1028 - loss: 0.3947 - val_accuracy: 0.1550 - val_loss: 0.3489\n",
      "Epoch 49/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1263 - loss: 0.3823 - val_accuracy: 0.1510 - val_loss: 0.3468\n",
      "Epoch 50/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1174 - loss: 0.3853 - val_accuracy: 0.1420 - val_loss: 0.3450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "d:\\AI Zaki_env\\zaki_env\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.0841 - loss: 0.6710 - val_accuracy: 0.1100 - val_loss: 0.5517\n",
      "Epoch 2/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.1087 - loss: 0.5519 - val_accuracy: 0.1260 - val_loss: 0.5200\n",
      "Epoch 3/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0969 - loss: 0.5288 - val_accuracy: 0.0970 - val_loss: 0.5048\n",
      "Epoch 4/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0982 - loss: 0.5074 - val_accuracy: 0.0590 - val_loss: 0.4926\n",
      "Epoch 5/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0853 - loss: 0.4957 - val_accuracy: 0.0670 - val_loss: 0.4818\n",
      "Epoch 6/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.0933 - loss: 0.4879 - val_accuracy: 0.0780 - val_loss: 0.4745\n",
      "Epoch 7/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.0905 - loss: 0.4767 - val_accuracy: 0.0690 - val_loss: 0.4675\n",
      "Epoch 8/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0940 - loss: 0.4718 - val_accuracy: 0.0880 - val_loss: 0.4628\n",
      "Epoch 9/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1012 - loss: 0.4715 - val_accuracy: 0.0930 - val_loss: 0.4536\n",
      "Epoch 10/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0902 - loss: 0.4631 - val_accuracy: 0.0560 - val_loss: 0.4496\n",
      "Epoch 11/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1025 - loss: 0.4569 - val_accuracy: 0.0910 - val_loss: 0.4428\n",
      "Epoch 12/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0928 - loss: 0.4484 - val_accuracy: 0.0770 - val_loss: 0.4368\n",
      "Epoch 13/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1123 - loss: 0.4493 - val_accuracy: 0.1090 - val_loss: 0.4359\n",
      "Epoch 14/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1120 - loss: 0.4457 - val_accuracy: 0.0750 - val_loss: 0.4263\n",
      "Epoch 15/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0969 - loss: 0.4392 - val_accuracy: 0.0830 - val_loss: 0.4208\n",
      "Epoch 16/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.0985 - loss: 0.4381 - val_accuracy: 0.0970 - val_loss: 0.4160\n",
      "Epoch 17/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0973 - loss: 0.4359 - val_accuracy: 0.0950 - val_loss: 0.4147\n",
      "Epoch 18/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1228 - loss: 0.4339 - val_accuracy: 0.1150 - val_loss: 0.4092\n",
      "Epoch 19/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1293 - loss: 0.4313 - val_accuracy: 0.0880 - val_loss: 0.4045\n",
      "Epoch 20/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1132 - loss: 0.4191 - val_accuracy: 0.0920 - val_loss: 0.4006\n",
      "Epoch 21/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1163 - loss: 0.4210 - val_accuracy: 0.1060 - val_loss: 0.3987\n",
      "Epoch 22/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1116 - loss: 0.4156 - val_accuracy: 0.1200 - val_loss: 0.3961\n",
      "Epoch 23/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1100 - loss: 0.4209 - val_accuracy: 0.1220 - val_loss: 0.4032\n",
      "Epoch 24/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1380 - loss: 0.4137 - val_accuracy: 0.1240 - val_loss: 0.3874\n",
      "Epoch 25/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1305 - loss: 0.4113 - val_accuracy: 0.1170 - val_loss: 0.3837\n",
      "Epoch 26/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1127 - loss: 0.4078 - val_accuracy: 0.1520 - val_loss: 0.3816\n",
      "Epoch 27/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1264 - loss: 0.4003 - val_accuracy: 0.1600 - val_loss: 0.3757\n",
      "Epoch 28/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1225 - loss: 0.4015 - val_accuracy: 0.1330 - val_loss: 0.3722\n",
      "Epoch 29/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1333 - loss: 0.4039 - val_accuracy: 0.1640 - val_loss: 0.3685\n",
      "Epoch 30/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1303 - loss: 0.4008 - val_accuracy: 0.1790 - val_loss: 0.3652\n",
      "Epoch 31/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1416 - loss: 0.3971 - val_accuracy: 0.1860 - val_loss: 0.3655\n",
      "Epoch 32/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.1340 - loss: 0.3957 - val_accuracy: 0.2150 - val_loss: 0.3587\n",
      "Epoch 33/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1590 - loss: 0.3920 - val_accuracy: 0.1350 - val_loss: 0.3558\n",
      "Epoch 34/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1477 - loss: 0.3914 - val_accuracy: 0.2050 - val_loss: 0.3501\n",
      "Epoch 35/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1591 - loss: 0.3868 - val_accuracy: 0.2370 - val_loss: 0.3462\n",
      "Epoch 36/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1714 - loss: 0.3793 - val_accuracy: 0.1900 - val_loss: 0.3456\n",
      "Epoch 37/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1677 - loss: 0.3807 - val_accuracy: 0.2130 - val_loss: 0.3428\n",
      "Epoch 38/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1704 - loss: 0.3748 - val_accuracy: 0.2690 - val_loss: 0.3394\n",
      "Epoch 39/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1959 - loss: 0.3751 - val_accuracy: 0.2330 - val_loss: 0.3349\n",
      "Epoch 40/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1789 - loss: 0.3729 - val_accuracy: 0.2120 - val_loss: 0.3303\n",
      "Epoch 41/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2126 - loss: 0.3722 - val_accuracy: 0.2610 - val_loss: 0.3306\n",
      "Epoch 42/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.2010 - loss: 0.3646 - val_accuracy: 0.2650 - val_loss: 0.3250\n",
      "Epoch 43/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1910 - loss: 0.3616 - val_accuracy: 0.2340 - val_loss: 0.3189\n",
      "Epoch 44/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2163 - loss: 0.3637 - val_accuracy: 0.2820 - val_loss: 0.3151\n",
      "Epoch 45/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1945 - loss: 0.3601 - val_accuracy: 0.3000 - val_loss: 0.3121\n",
      "Epoch 46/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2162 - loss: 0.3585 - val_accuracy: 0.2570 - val_loss: 0.3118\n",
      "Epoch 47/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2101 - loss: 0.3586 - val_accuracy: 0.2630 - val_loss: 0.3094\n",
      "Epoch 48/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.1967 - loss: 0.3554 - val_accuracy: 0.3090 - val_loss: 0.3095\n",
      "Epoch 49/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2115 - loss: 0.3539 - val_accuracy: 0.2620 - val_loss: 0.3006\n",
      "Epoch 50/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.2263 - loss: 0.3479 - val_accuracy: 0.3510 - val_loss: 0.2984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A (Minor-only): Accuracy = 14.20% | Loss = 0.3450\n",
      "Model B (Full-data): Accuracy = 35.10% | Loss = 0.2984\n",
      "\n",
      "ğŸ“Š Model A (Minor-only) Results:\n",
      "Accuracy: 14.20% | Loss: 0.3450\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\n",
      "ğŸ” Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Weak       0.89      0.96      0.92     10689\n",
      "        Weak       0.88      0.71      0.78      4311\n",
      "\n",
      "    accuracy                           0.89     15000\n",
      "   macro avg       0.88      0.83      0.85     15000\n",
      "weighted avg       0.89      0.89      0.88     15000\n",
      "\n",
      "[[10253   436]\n",
      " [ 1256  3055]]\n",
      "\n",
      "ğŸ“Š Model B (Full-data) Results:\n",
      "Accuracy: 35.10% | Loss: 0.2984\n",
      "\u001b[1m32/32\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\n",
      "ğŸ” Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Not Weak       0.91      0.98      0.94     10807\n",
      "        Weak       0.94      0.74      0.83      4193\n",
      "\n",
      "    accuracy                           0.91     15000\n",
      "   macro avg       0.92      0.86      0.88     15000\n",
      "weighted avg       0.92      0.91      0.91     15000\n",
      "\n",
      "[[10618   189]\n",
      " [ 1111  3082]]\n",
      "Minor-only label distribution: [53214 21786]\n",
      "Full-data label distribution: [53645 21355]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\n",
      "Subject-wise Prediction Comparison (Sample Student):\n",
      "--------------------------------------------------------------\n",
      "Subject                                       Actual Weak (A) Predicted (A)   Actual Weak (B) Predicted (B)  \n",
      "--------------------------------------------------------------\n",
      "Algorithm_&_Program_Design                    No              No              No              No             \n",
      "Database_Management_Systems                   No              No              No              No             \n",
      "Programming_with_Java                         No              No              No              No             \n",
      "Digital_Logic_&_Computer_Architecture         No              No              No              No             \n",
      "Software_Engineering                          No              No              No              No             \n",
      "Theoretical_Computer_Science                  No              No              No              No             \n",
      "Advanced_Data_Structures                      No              No              No              No             \n",
      "Data_Communication_&_Networks                 No              No              No              No             \n",
      "Operating_Systems_&_Shell_Programming         No              No              No              No             \n",
      "AI_&_ML                                       Yes             Yes             No              No             \n",
      "Software_Testing_&_QA                         No              No              No              No             \n",
      "Analysis_&_Design_of_Algorithms               No              No              No              No             \n",
      "Data_Mining_&_Warehousing                     No              No              No              No             \n",
      "Information_&_Cybersecurity                   No              No              No              No             \n",
      "Cloud_Computing                               No              No              No              No             \n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import joblib\n",
    "\n",
    "# Load dataset (with archetypes and masking logic)\n",
    "df = pd.read_csv(\"MCA_Student_Performance_Balanced.csv\")\n",
    "subjects = [col.replace(\"_Minor1\", \"\") for col in df.columns if \"_Minor1\" in col]\n",
    "\n",
    "def prepare_features_targets(df, subjects, threshold, include_endsem=True):\n",
    "    feature_columns = []\n",
    "    target_columns = []\n",
    "    for sub in subjects:\n",
    "        feature_columns.extend([f\"{sub}_Minor1\", f\"{sub}_Minor2\"])\n",
    "        if include_endsem:\n",
    "            feature_columns.append(f\"{sub}_EndSem\")\n",
    "    X = df[feature_columns]\n",
    "    for sub in subjects:\n",
    "        min1 = df[f\"{sub}_Minor1\"]\n",
    "        min2 = df[f\"{sub}_Minor2\"]\n",
    "        endsem = df[f\"{sub}_EndSem\"] if include_endsem else 0\n",
    "        # For minors-only: threshold should be realistic for only two minors (e.g., 24 out of 40)\n",
    "        # For minors+endsem: threshold higher (e.g., 60 or another realistic sum)\n",
    "        total_score = min1 + min2 + (endsem if include_endsem else 0)\n",
    "        is_missing = (min1 == 0) & (min2 == 0) & ((endsem == 0) if include_endsem else True)\n",
    "        df[f\"{sub}_IsWeak\"] = np.where(is_missing, 0, (total_score < threshold).astype(int))\n",
    "        target_columns.append(f\"{sub}_IsWeak\")\n",
    "    y = df[target_columns]\n",
    "    return X, y\n",
    "\n",
    "def scale_and_split_save_scaler(X, y, scaler_filename):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    return train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def build_model(input_dim, output_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, input_dim=input_dim, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
    "        Dense(32, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.25),\n",
    "        Dense(output_dim, activation=\"sigmoid\")\n",
    "    ])\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Model A (Minors only): threshold = 24 (for two minors, each max 20)\n",
    "X_minor, y_minor = prepare_features_targets(df, subjects, 24, include_endsem=False)\n",
    "X_train_A, X_test_A, y_train_A, y_test_A = scale_and_split_save_scaler(X_minor, y_minor, \"minmax_scaler_minor.pkl\")\n",
    "model_A = build_model(X_train_A.shape[1], len(subjects))\n",
    "history_A = model_A.fit(X_train_A, y_train_A, validation_data=(X_test_A, y_test_A), epochs=50, batch_size=16, verbose=1)\n",
    "model_A.save(\"WeaknessPredictor_MinorsOnly.h5\")\n",
    "\n",
    "# Model B (Minors + EndSem): threshold = 60 (e.g. two minors + one endsem: each max 20/20/60)\n",
    "X_full, y_full = prepare_features_targets(df, subjects, 60, include_endsem=True)\n",
    "X_train_B, X_test_B, y_train_B, y_test_B = scale_and_split_save_scaler(X_full, y_full, \"minmax_scaler_full.pkl\")\n",
    "model_B = build_model(X_train_B.shape[1], len(subjects))\n",
    "history_B = model_B.fit(X_train_B, y_train_B, validation_data=(X_test_B, y_test_B), epochs=50, batch_size=16, verbose=1)\n",
    "model_B.save(\"WeaknessPredictor_FullData.h5\")\n",
    "\n",
    "# --- Evaluation & Metrics ---\n",
    "loss_A, acc_A = model_A.evaluate(X_test_A, y_test_A, verbose=0)\n",
    "loss_B, acc_B = model_B.evaluate(X_test_B, y_test_B, verbose=0)\n",
    "print(f\"Model A (Minor-only): Accuracy = {acc_A*100:.2f}% | Loss = {loss_A:.4f}\")\n",
    "print(f\"Model B (Full-data): Accuracy = {acc_B*100:.2f}% | Loss = {loss_B:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ“Š Model A (Minor-only) Results:\")\n",
    "print(f\"Accuracy: {acc_A*100:.2f}% | Loss: {loss_A:.4f}\")\n",
    "y_pred_A = (model_A.predict(X_test_A) > 0.5).astype(int)\n",
    "print(\"\\nğŸ” Overall Classification Report:\")\n",
    "print(classification_report(y_test_A.values.ravel(), y_pred_A.ravel(), target_names=[\"Not Weak\", \"Weak\"]))\n",
    "print(confusion_matrix(y_test_A.values.ravel(), y_pred_A.ravel()))\n",
    "\n",
    "print(\"\\nğŸ“Š Model B (Full-data) Results:\")\n",
    "print(f\"Accuracy: {acc_B*100:.2f}% | Loss: {loss_B:.4f}\")\n",
    "y_pred_B = (model_B.predict(X_test_B) > 0.5).astype(int)\n",
    "print(\"\\nğŸ” Overall Classification Report:\")\n",
    "print(classification_report(y_test_B.values.ravel(), y_pred_B.ravel(), target_names=[\"Not Weak\", \"Weak\"]))\n",
    "print(confusion_matrix(y_test_B.values.ravel(), y_pred_B.ravel()))\n",
    "\n",
    "print(\"Minor-only label distribution:\", np.bincount(y_minor.values.ravel()))\n",
    "print(\"Full-data label distribution:\", np.bincount(y_full.values.ravel()))\n",
    "\n",
    "# --- Sample predictions for a test student ---\n",
    "sample_A = np.expand_dims(X_test_A[0], axis=0)\n",
    "pred_A = (model_A.predict(sample_A)[0] > 0.5).astype(int)\n",
    "actual_A = y_test_A.iloc[0].values\n",
    "\n",
    "sample_B = np.expand_dims(X_test_B[0], axis=0)\n",
    "pred_B = (model_B.predict(sample_B)[0] > 0.5).astype(int)\n",
    "actual_B = y_test_B.iloc[0].values\n",
    "\n",
    "print(\"\\nSubject-wise Prediction Comparison (Sample Student):\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "print(f\"{'Subject':<45} {'Actual Weak (A)':<15} {'Predicted (A)':<15} {'Actual Weak (B)':<15} {'Predicted (B)':<15}\")\n",
    "print(\"--------------------------------------------------------------\")\n",
    "for i, sub in enumerate(subjects):\n",
    "    a_actual = \"Yes\" if actual_A[i] == 1 else \"No\"\n",
    "    a_pred = \"Yes\" if pred_A[i] == 1 else \"No\"\n",
    "    b_actual = \"Yes\" if actual_B[i] == 1 else \"No\"\n",
    "    b_pred = \"Yes\" if pred_B[i] == 1 else \"No\"\n",
    "    print(f\"{sub:<45} {a_actual:<15} {a_pred:<15} {b_actual:<15} {b_pred:<15}\")\n",
    "print(\"--------------------------------------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zaki_env (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
